Evaluation

batch_size=10
char_cnn_filter_num=30
char_embeddings_dim=25
char_window_size=3
check_for_lowercase=True
clip_grad=5
cross_fold_id=-1
cross_folds_num=-1
data_io='connl-ner-2003'
dataset_sort=False
dev='data/NER/CoNNL_2003_shared_task/dev.txt'
dropout_ratio=0.5
emb_delimiter=' '
emb_dim=100
emb_fn='embeddings/oldcatalanmodel.vec'
emb_load_all=False
epoch_num=100
evaluator='token-acc'
freeze_char_embeddings=False
freeze_word_embeddings=False
gpu=-1
load=None
lr=0.01
lr_decay=0.05
min_epoch_num=50
model='BiRNNCNNCRF'
momentum=0.9
opt='sgd'
patience=15
report_fn='2021_01_04_17-15_26_report.txt'
rnn_hidden_dim=100
rnn_type='LSTM'
save='2021_01_04_17-15_26_tagger.hdf5'
save_best=True
seed_num=42
test='data/NER/CoNNL_2003_shared_task/test.txt'
train='data/NER/CoNNL_2003_shared_task/train.txt'
verbose=True
word_len=20
word_seq_indexer=None

         epoch  |     train loss | token-acc-train |  token-acc-dev | token-acc-test 
---------------------------------------------------------------------------------------
              0 |           0.00 |           0.05 |           0.04 |           0.04 
              1 |        7305.48 |           0.38 |           0.41 |           0.42 
              2 |        5844.10 |           0.58 |           0.55 |           0.57 
              3 |        5008.05 |           0.65 |           0.61 |           0.65 
              4 |        3775.48 |           0.66 |           0.62 |           0.64 
              5 |        3539.41 |           0.71 |           0.65 |           0.70 
              6 |        2755.56 |           0.68 |           0.63 |           0.68 
              7 |        2770.39 |           0.74 |           0.70 |           0.72 
              8 |        2688.99 |           0.74 |           0.69 |           0.72 
              9 |        3590.60 |           0.74 |           0.70 |           0.72 
             10 |        3391.01 |           0.76 |           0.71 |           0.73 
             11 |        2265.56 |           0.78 |           0.72 |           0.76 
             12 |        2448.47 |           0.78 |           0.71 |           0.75 
             13 |        1939.89 |           0.80 |           0.73 |           0.78 
             14 |        2287.65 |           0.79 |           0.72 |           0.77 
             15 |        1820.49 |           0.80 |           0.73 |           0.78 
             16 |        2389.74 |           0.81 |           0.73 |           0.80 
             17 |        2208.03 |           0.80 |           0.72 |           0.78 
             18 |        1975.08 |           0.82 |           0.74 |           0.79 
             19 |        2737.19 |           0.83 |           0.74 |           0.80 
             20 |        2565.51 |           0.84 |           0.76 |           0.80 
             21 |        2132.40 |           0.82 |           0.75 |           0.79 
             22 |        1970.53 |           0.83 |           0.77 |           0.81 
             23 |        1624.06 |           0.84 |           0.77 |           0.82 
             24 |        2365.95 |           0.85 |           0.76 |           0.81 
             25 |        1842.77 |           0.85 |           0.77 |           0.81 
             26 |        2205.63 |           0.85 |           0.77 |           0.81 
             27 |        1743.44 |           0.84 |           0.76 |           0.81 
             28 |        1655.68 |           0.85 |           0.77 |           0.82 
             29 |        1320.58 |           0.85 |           0.77 |           0.83 
             30 |        1715.48 |           0.86 |           0.78 |           0.83 
             31 |        1602.21 |           0.86 |           0.78 |           0.84 
             32 |        2102.69 |           0.87 |           0.79 |           0.84 
             33 |        1909.54 |           0.87 |           0.79 |           0.84 
             34 |        1428.16 |           0.88 |           0.79 |           0.85 
             35 |        1568.47 |           0.88 |           0.78 |           0.85 
             36 |        1685.11 |           0.87 |           0.78 |           0.83 
             37 |        1804.85 |           0.88 |           0.79 |           0.84 
             38 |        1460.39 |           0.88 |           0.80 |           0.84 
             39 |        2121.07 |           0.89 |           0.80 |           0.85 
             40 |        1405.94 |           0.88 |           0.80 |           0.85 
             41 |        1322.75 |           0.88 |           0.79 |           0.86 
             42 |        1203.46 |           0.88 |           0.79 |           0.85 
             43 |        1415.57 |           0.89 |           0.79 |           0.85 
             44 |        1403.73 |           0.88 |           0.79 |           0.86 
             45 |        1379.42 |           0.88 |           0.78 |           0.85 
             46 |        2060.38 |           0.90 |           0.80 |           0.85 
             47 |        1158.21 |           0.89 |           0.81 |           0.86 
             48 |        1226.38 |           0.88 |           0.79 |           0.86 
             49 |        1677.76 |           0.90 |           0.79 |           0.87 
             50 |        1774.99 |           0.89 |           0.80 |           0.86 
             51 |        1437.67 |           0.90 |           0.81 |           0.87 
             52 |        1273.08 |           0.90 |           0.80 |           0.86 
             53 |        1232.90 |           0.89 |           0.79 |           0.86 
             54 |        1243.14 |           0.90 |           0.81 |           0.86 
             55 |        1339.15 |           0.89 |           0.80 |           0.86 
             56 |        1477.32 |           0.88 |           0.78 |           0.85 
             57 |        1056.43 |           0.90 |           0.80 |           0.87 
             58 |        1450.57 |           0.90 |           0.81 |           0.86 
             59 |        1027.03 |           0.91 |           0.80 |           0.87 
             60 |        1428.68 |           0.90 |           0.80 |           0.86 
             61 |        1404.88 |           0.90 |           0.80 |           0.87 
             62 |         989.13 |           0.90 |           0.81 |           0.87 
             63 |        1179.22 |           0.89 |           0.80 |           0.86 
---------------------------------------------------------------------------------------
Final eval on test, "save best", best epoch on dev 47, token-acc, test = 0.86)
---------------------------------------------------------------------------------------*** Token-level F1 score: 0.86% ***
Input arguments:
python3 main.py -1

0.8551